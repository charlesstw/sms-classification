{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltpbJIf8U0Qs"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# ğŸ“Œ è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer\n",
    "model_dir = \"./results\"  # å¦‚æœä½ æ˜¯æ”¾åœ¨å…¶ä»–è³‡æ–™å¤¾ï¼Œè«‹æ”¹é€™è£¡\n",
    "tokenizer_dir = \"./results\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")  # âœ… é‡æ–°å¾ huggingface ä¸‹è¼‰\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# âœ… åˆ‡æ›åˆ°è©•ä¼°æ¨¡å¼\n",
    "model.eval()\n",
    "\n",
    "# ğŸ“Œ åˆ¤æ–·ç°¡è¨Šæ˜¯å¦å«äººåçš„å‡½å¼\n",
    "def predict_person_name(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return \"âœ… å«äººå\" if predicted_label == 1 else \"âŒ ä¸å«äººå\"\n",
    "\n",
    "# ğŸ“Œ æ¸¬è©¦ç¯„ä¾‹\n",
    "test_samples = [\n",
    "    \"[æ¬Šç›Šé€šçŸ¥] ä½ å°‡æœ‰æ©Ÿæœƒèˆ‡æ¡‚ç¶¸é‚ã€ç‹æŸå‚‘ä¸€åŒåƒèˆ‡Disney+ã€Šå°åŒ—å¥³å­åœ–é‘‘ã€‹é¦–æ˜ æœƒ! æ´»å‹•è©³æƒ…è«‹è¦‹â†’ twm5g.co/aAWQ\",\n",
    "    \"è«‹å•æ‚¨è¦ä¿ç•™æˆ–å–æ¶ˆ1æœˆ20æ—¥ 19:30 æ—¥æœˆæ½­åŠ›éº—æº«å¾·å§†æº«æ³‰é…’åº— é¥—æ² å…¨æ—¥é¤å»³è¨‚ä½å—ï¼Ÿé»é¸é€£çµå›è¦†ï¼š https://iln.io/345dyt\",\n",
    "    \"é -Nisekoç¾Šè¹„å±±æ¯é€é”å…­å¼µé»åº—ï¼Œé™é‡ç·¨è™ŸA029205310è«‹å‰å¾€å–è²¨ï¼Œå¯è‡³å…¨å®¶APPé¦–é >åŒ…è£¹æŸ¥è©¢\",\n",
    "    \"ã€å¤§æ¨¹é€Ÿè²¸ã€‘æœ€å¿«5åˆ†é˜è³‡é‡‘å…¥è¢‹!è¦ªæ„›çš„ç‹æœé¾å…ˆç”Ÿï¼Œåœ‹æ³°ä¸–è¯éŠ€è¡Œå¹«æ‚¨é¦¬ä¸Šè§£æ±ºè³‡é‡‘ç…©æƒ±ï¼Œæ•¸ä½ç”³è²¸è¶…ç°¡å–®ã€‚è³‡é‡‘å¿«é€Ÿå…¥è¢‹ https://cathaybk.tw/C3ACZ78YJ ã€‚ç¸½è²»ç”¨å¹´ç™¾åˆ†ç‡3.62%~17.09%ã€‚\",\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“Š é æ¸¬çµæœï¼š\")\n",
    "for text in test_samples:\n",
    "    print(f\"ğŸ‘‰ ã€{text}ã€ â†’ {predict_person_name(text)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMJkPnlVwbhsJ+SIQrfLaTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
