{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltpbJIf8U0Qs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é æ¸¬å®Œæˆï¼Œå·²è¼¸å‡ºç‚º sms_with_name_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "### 0. ä¸Šå‚³è¦æª¢æŸ¥çš„ csv æª” sms.csv ###\n",
    "###    ä¸Šå‚³ train_name ç”¢å‡ºçš„æ¨¡å‹ zip ###\n",
    "# === 1. è§£å£“ç¸®æ¨¡å‹ zipï¼ˆå¯ç•¥éè‹¥å·²è§£å£“ï¼‰\n",
    "# with ZipFile(\"/content/model_results.zip\", 'r') as zip_ref:\n",
    "    # zip_ref.extractall(\"results\")\n",
    "\n",
    "# === 2. è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer\n",
    "dir = \"./results/final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(dir)\n",
    "model = BertForSequenceClassification.from_pretrained(dir)\n",
    "model.eval()\n",
    "\n",
    "# === 3. è®€å– CSV æª”æ¡ˆï¼ˆåŒ…å«ç°¡è¨Šæ–‡å­—æ¬„ä½ï¼‰\n",
    "df = pd.read_csv(\"å·²é©—è­‰0709/naming_0_3w.csv\")  # âœ… ä½ è¦é æ¸¬çš„ç°¡è¨Š CSV æª”æ¡ˆ\n",
    "assert \"text\" in df.columns, \"âš ï¸ è«‹ç¢ºèªä½ çš„ CSV åŒ…å« text æ¬„ä½\"\n",
    "\n",
    "# === 4. å®šç¾©é æ¸¬å‡½å¼ï¼ˆå›å‚³é¡åˆ¥èˆ‡é¡åˆ¥1æ©Ÿç‡%ï¼‰\n",
    "def predict_person_name_with_prob(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return pd.Series([0, 0.0])  # é è¨­ä¸å«åˆ†é¡ã€æ©Ÿç‡ç‚º 0%\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = softmax(logits, dim=1).squeeze().tolist()  # è½‰ç‚ºæ©Ÿç‡\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "        prob_person_name = round(probs[1] * 100, 2)  # é¡åˆ¥ 1 çš„æ©Ÿç‡ (%)\n",
    "\n",
    "    return pd.Series([predicted_label, prob_person_name])\n",
    "\n",
    "# === 5. å¥—ç”¨åˆ°æ•´å€‹æ¬„ä½ï¼Œæ–°å¢å…©æ¬„\n",
    "df[[\"has_person_name\", \"prob_person_name_percent\"]] = df[\"text\"].apply(predict_person_name_with_prob)\n",
    "\n",
    "# === 6. è¼¸å‡ºçµæœåˆ°æ–°çš„ CSV æª”\n",
    "df.to_csv(\"sms_with_name_predictions.csv\", index=False)\n",
    "print(\"âœ… é æ¸¬å®Œæˆï¼Œå·²è¼¸å‡ºç‚º sms_with_name_predictions.csv\")\n",
    "\n",
    "\n",
    "# # ğŸ“Œ æ¸¬è©¦ç¯„ä¾‹\n",
    "# test_samples = [\n",
    "#     \"ğŸ‘§\",\n",
    "#     \"æ²ˆå˜‰å„€æ˜å¤©è¦‹ï¼Œè¨˜å¾—å¸¶æ¯›å·¾ã€æ°´ã€è£œçµ¦å“ã€‚\",\n",
    "#     \"é -Nisekoç¾Šè¹„å±±æ¯é€é”å…­å¼µé»åº—ï¼Œé™é‡ç·¨è™ŸA029205310è«‹å‰å¾€å–è²¨ï¼Œå¯è‡³å…¨å®¶APPé¦–é >åŒ…è£¹æŸ¥è©¢\",\n",
    "#     \"ã€å¤§æ¨¹é€Ÿè²¸ã€‘æœ€å¿«5åˆ†é˜è³‡é‡‘å…¥è¢‹!è¦ªæ„›çš„ç‹å…ˆç”Ÿï¼Œåœ‹æ³°ä¸–è¯éŠ€è¡Œå¹«æ‚¨é¦¬ä¸Šè§£æ±ºè³‡é‡‘ç…©æƒ±ï¼Œæ•¸ä½ç”³è²¸è¶…ç°¡å–®ã€‚è³‡é‡‘å¿«é€Ÿå…¥è¢‹ https://cathaybk.tw/C3ACZ78YJ ã€‚ç¸½è²»ç”¨å¹´ç™¾åˆ†ç‡3.62%~17.09%ã€‚\",\n",
    "# ]\n",
    "\n",
    "# print(\"\\nğŸ“Š é æ¸¬çµæœï¼š\")\n",
    "# for text in test_samples:\n",
    "#     print(f\"ğŸ‘‰ ã€{text}ã€ â†’ {predict_person_name(text)}\")\n",
    "\n",
    "\n",
    "# # å…ˆæ‰¾å‡º text æ˜¯ç©ºå­—ä¸²æˆ–ç©ºç™½çš„ row\n",
    "# empty_or_null_mask = df[\"text\"].isna()\n",
    "# empty_text_ids = df[empty_or_null_mask][\"Id\"]\n",
    "\n",
    "# # å°å‡ºä¾†\n",
    "# for eid in empty_text_ids:\n",
    "#     print(f\"Empty text at ID: {eid}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMJkPnlVwbhsJ+SIQrfLaTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
